{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data from the internet\n",
    "\n",
    "Based on materials by Ben Lewis (available at https://wiki.communitydata.cc/Wikipedia_(CDSW))\n",
    "\n",
    "There is a lot of interesting data on the internet. Some of the websites that have this data provide ways for computers to read this data. We call these ways \"Web APIs\", where API stands for \"Application Programming Interface\". It's called that, because it's a way for you to connect your program to the website. \n",
    "\n",
    "For example, you can get data from Wikipedia about different articles, who is editing them, how often they get edited, and when. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an introduction to the [MediaWiki API][mw-api]; MediaWiki is the\n",
    "software that runs Wikipedia and associated projects, and it exposes an API that lets users write queries and get information back about practically any part of Wikipedia. The site I linked to describes the API and all its various features, in more depth than we'll cover here.\n",
    "\n",
    "[mw-api]: https://www.mediawiki.org/wiki/API:Main_page \"API documentation.\"\n",
    "\n",
    "## Making a call and parsing the pieces\n",
    "\n",
    "We will use the Python `requests` library to make requests for data from the Wikipedia API. Here is what a request might look like:\n",
    "\n",
    "    import requests\n",
    "    ENDPOINT = 'https://en.wikipedia.org/w/api.php'\n",
    "    wp_call = requests.get(ENDPOINT + '?'\n",
    "        + 'action=query&'\n",
    "        + 'prop=links&'\n",
    "        + 'titles=User:Zen-ben&'\n",
    "        + 'continue=&'\n",
    "        + 'format=json')\n",
    "\n",
    "What we have above is a call to the _Wikipedia API_. I've broken this apart into separate, concatenated stanzas to make each section stand alone, but it would work as one string too. This makes explaining each part easier, and provides a clean segue into the next way we'll call this code.\n",
    "\n",
    "### The endpoint\n",
    "\n",
    "The string `https://en.wikipedia.org/w/api.php` is the _endpoint_ for this call; this is the URL for the API itself. The part of the URL after the question mark is called the _query_, and it defines the work you want the API to perform.\n",
    "\n",
    "In order to avoid writing the same string over and over again, as well as avoid errors, I've declared a variable called `ENDPOINT` for this specific string. (It's all-caps to remind me to never write anything to it, only to read from it.) We'll be using this string every time we make a request.\n",
    "\n",
    "### The query\n",
    "\n",
    "A query is a list of parameters you pass to a server as a part of a URL; not every URL has them (in fact, most sites you browse to don't have them. They're only really common when interacting with APIs.) The query in our request above is everything that comes after the question mark; it separates the query from the _path_, which in this case is `/w/api.php`. The query is composed of parameter/value pairs, which have the form `parameter=value` and are separated with ampersands (`&`).\n",
    "\n",
    "#### Action\n",
    "By setting `action=query`, we're requesting information from the Wikipedia servers. Note that this _query_ is unrelated to the _query string_; if we wanted to edit Wikipedia via the API (which is possible, the syntax is different and outside the scope of this session), we would write `action=edit` instead. The `action` parameter is required in a MediaWiki API call.\n",
    "\n",
    "##### Action parameter: Property\n",
    "Using `prop=links` tells the API we want information about links on a page (or pages) that we haven't specified yet. (That's in another parameter.)\n",
    "\n",
    "##### Action parameter: Titles\n",
    "The field `titles=User:Zen-ben` specifies that this query should return results about the page about the \"User:Zen-ben\" page; this is my user page on Wikipedia. If you go to https://en.wikipedia.org/wiki/User:Zen-ben, you'll see that the format of the address to actually view my user page is the same as the requested format here. This is not a coincidence; if you want to try another page, look it up on Wikipedia and switch that name in here instead. (I recommend experimenting!)\n",
    "\n",
    "##### Action parameter: Continue\n",
    "By supplying `continue=` with our query, we can get additional data in further responses if there's more to our query than the response provides. (We'll use this later.) Note that this paramter is supplied without a value. This is acceptable.\n",
    "\n",
    "#### Format\n",
    "The data we get back from the Wikipedia API needs to have some structure; when we provide the `format=json` string, we are requesting that our response be formatted in JSON, which we have easy ways to handle (in particular, requests has good support for it already.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the results of our query\n",
    "After calling the Wikipedia API, we have a response stored in the `wp_call` variable. If we want to do anything with it, though, we need it in a form we know how to deal with.\n",
    "\n",
    "    response = wp_call.json()\n",
    "\n",
    "This function turns the JSON response we got from Wikipedia into a \n",
    "Python dictionary we can access. From here, we can start looking for interesting pieces. To start, we'll just iterate through the responses we have. You can go ahead and just see the structure of `response` by typing it at your console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that it's a dictionary with dictionaries inside of it. When you first get a response from a web API, it can be hard to tell what's\n",
    "actually in the response. Printing the JSON will tell you something, but it's hard to read and very dense. After expanding the JSON into a dictionary with the `json()` function, you can explore the contents of the dictionary. For example, what are the keys?\n",
    "\n",
    "    response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us we have two keys in the response dictionary, `'continue'` and `'query'`. We'll leave the `'continue'` key alone for now, and focus on `'query'` for the time being. The `'query'` key is actually the response to the query we just made, somewhat confusingly, but we can now explore what it is. The fastest way to check is to use the `type()` function to see what type the value\n",
    "is:\n",
    "\n",
    "    type(response['query'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that `response['query']` is a dictionary, so we can call `.keys()` on it:\n",
    "\n",
    "    response['query'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there's only one key in the `response['query']` dictionary; I'm going to pull the value of that key out of the response, now, and put it in its own variable so I don't have to keep rewriting all of these strings:\n",
    "\n",
    "    pages = response['query']['pages']\n",
    "    pages.keys()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us how to get the content of that dictionary\n",
    "\n",
    "    dict_keys(['44376332'])\n",
    "    pages['44376332'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here, I've dug down a few more layers. That long number there is actually the `'pageid'` of Ben's userpage; it's the identifier that Wikipedia uses internally to find this page. `'ns'` is short for namespace; the page is in the `User` namespace, which is namespace number 2 (but that's not important to our current discussion.) Instead, let's look at the `'links'` key, which has the details we're interested in:\n",
    "\n",
    "    user_page = pages['44376332']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so this is a list. Now instead of indexing by key, I need to index by ... well, index. So we can see what the type of the first element in the list is:\n",
    "\n",
    "    type(user_page['links'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I happen to know that there are the keys `'title'` and `'ns'` (there's that namespace again) inside this dictionary; we only really care about the `'title'` key right now, however.\n",
    "\n",
    "To recap: we're looking at a dictionary that contains a dictionary that contains a dictionary that contains a list of dictionaries. Wow, that's a lot to keep track of. Oh, and we want to do the same thing for each item in that list. We know how to do that, though, because we have loops!\n",
    "\n",
    "Instead of just using my handy `user_page` variable here, I'm going to make my loop a bit more general than just working with this single user page, so that we can reuse it (or something similar) in the future. At first, I just want to see the title of the pages (or single page) in the response:\n",
    "\n",
    "    for page in response['query']['pages']:\n",
    "        print(response['query']['pages'][page]['title'])\n",
    "\n",
    "Okay, so that printed out the title of the page. But we can do more with this! Now if we create _another_ loop inside of that loop, we can iterate over the links in the list of links, and print _their_ titles:\n",
    "\n",
    "    for page in response[\"query\"][\"pages\"]:\n",
    "        for link in response['query']['pages'][page]['links']:\n",
    "            print(link['title'])\n",
    "\n",
    "Now we've explored the structure of our query's response, and even built _nested loops_ to see the contents of a list inside a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a better API call\n",
    "That last call got us the information we needed, but it was a very long string to write. Instead, the requests library has a better way to build an API call, using a dictionary!\n",
    "\n",
    "## Parameters dictionary\n",
    "In requests, we can supply a dictionary of parameters with our request. So,\n",
    "let's create our dictionary:\n",
    "\n",
    "    parameters = {'action' : 'query',\n",
    "                  'prop' : 'links',\n",
    "                  'titles' : 'User:Zen-ben',\n",
    "                  'format' : 'json',\n",
    "                  'continue' : ''}\n",
    "\n",
    "As you read each line, look back at the query we used before; note how instead of each field being `\"field=value&\"`, now they're keys and values. We can run our query again, this time without building that big huge string:\n",
    "\n",
    "    wp_call = requests.get(ENDPOINT, params=parameters)\n",
    "\n",
    "Now the reason for creating a variable to store the endpoint URL makes more sense; suddenly, instead of having to rewrite that long string, you just have to type out the variable name. \n",
    "\n",
    "We're going to use a slightly different call structure this time, and take advantage of a field I mentioned but didn't do much with last time: the continue field.\n",
    "\n",
    "    while True:\n",
    "        wp_call = requests.get('https://en.wikipedia.org/w/api.php', params=parameters)\n",
    "        response = wp_call.json()\n",
    "\n",
    "        for page in response[\"query\"][\"pages\"]:\n",
    "            for link in response['query']['pages'][page]['links']:\n",
    "                print(link['title'])\n",
    "\n",
    "        if 'continue' in response:\n",
    "            parameters['continue'] = response['continue']['continue']\n",
    "            parameters['plcontinue'] = response['continue']['plcontinue']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "Now, this block uses the \"while true\" idiom; basically, the loop will run until you use the `break` keyword to force Python to exit the loop. We do this here to take advantage of the continue field, because now you can call back to the API and get more results (as you can see, there's more to the results printed this time as opposed to before.) Basically, the continue field is a token that the server uses to identify when a request isn't quite done, and you want to get more results. By returning the exact string that the server sent, you're requesting specifically the rest of the results for your query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding the query\n",
    "\n",
    "We can add to this query and get link information for more than one page; let's also look at Mako's user page:\n",
    "\n",
    "    parameters['titles'] = parameters['titles] + '|User:Benjamin Mako Hill'\n",
    "\n",
    "We're also going to switch from printing out the contents of the response to storing the links in lists instead, in a dictionary where the keys are the names of our pages:\n",
    "\n",
    "    page_links = {}\n",
    "\n",
    "Now we're going to build a slightly different loop than we had before, because we need to make sure each list is present before we change it:\n",
    "\n",
    "    while True:\n",
    "        wp_call = requests.get(ENDPOINT, params=parameters)\n",
    "        response = wp_call.json()\n",
    "\n",
    "        for page in response['query']['pages']:\n",
    "            page_title = response['query']['pages'][page]['title']\n",
    "            if page_title not in page_links:\n",
    "                page_links[page_title] = []\n",
    "            if 'links' in response['query']['pages'][page]:\n",
    "                page_links[page_title].extend(response['query']['pages'][page]['links'])\n",
    "\n",
    "        if 'continue' in response:\n",
    "            parameters['continue'] = response['continue']['continue']\n",
    "            parameters['plcontinue'] = response['continue']['plcontinue']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "Now we're building our dictionary of lists; because we'll sometimes not get links for one page or another (it'll first give us links from Mako's user page, and then it'll give links from Ben's) we need to test for the presence of the `'links'` entry in the response dictionary. This is a good example of what's called _sanitizing input_, or verifying that the data we're getting is in a usable form. There's a lot of examples of unsanitized data causing unexpected problems in software. In this case, a missing `'links'` key is completely expected, so we're fine with that value not being present. In others, it would be an error that would require exiting before something bad happened. (Figuring out when missing data is safe isn't easy, but it's not impossible either. Ask me about it!)\n",
    "\n",
    "Now that we have our data, we could run some rough statistics on it, like how many entries there are, how many are shared between the two pages, if each shows up in the other ... there's a lot of information to be had just from this set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting revisions to an article\n",
    "We've now learned how to build a query, how to look for different pieces, and how to modify our basic query. Instead of continuing to look at links for the moment, let's look into what we can do with another type of data the Wikipedia API offers: revisions to articles.\n",
    "\n",
    "Each _revision_ is a separate change to a Wikipedia article. The revision datatype in the Wikipedia API captures all sorts of data about the change made, in addition to the actual content of the change; it captures the username (or another identifier, we'll talk about that in a moment), the time the change was made, the comment the user making the change left in the comment field, and a hash of the change (a unique number generated from the content of the change to represent it.) We'll be looking at usernames and a flag that gets set for some of them. (A flag is a boolean value, `true` or `false`, which is normally `false` unless some specific condition is met.)\n",
    "\n",
    "As before, there's much more to this API than what we're covering here. I recommend visiting the API documentation and reading more there.\n",
    "\n",
    "## Looking for anonymous editors\n",
    "One of Wikipedia's greatest strengths (or weaknesses) is that it allows anonymous editors; people who haven't logged into the site can edit its contents. This both allows people who don't want to (or don't care to) create accounts to contribute, but also makes tracking contributions a bit harder.\n",
    "\n",
    "Let's take some time to look at who's contributing to the article on Python! But first, let's introduce a new kind of loop.\n",
    "\n",
    "### While loops: looping on an indeterminate condition\n",
    "So we have for loops. They're great, they let us iterate through items in a list or keys in a dictionary. But what if we don't know how long something will take? Then we need some other sort of loop. The `while` loop checks its condition before running, then runs the loop and re-checks the condition. As long as its condition is true, it will continue running.\n",
    "\n",
    "    iter = 0\n",
    "    while iter < 10:\n",
    "        iter = iter + 1\n",
    "        print(iter)\n",
    "\n",
    "\n",
    "    iter = 0\n",
    "    while True:\n",
    "        iter = iter + 1\n",
    "        print(iter)\n",
    "        if iter > 9:\n",
    "            break\n",
    "\n",
    "The keyword `break` tells Python to exit the loop it's currently in. It's a fast way to exit a loop when you've found the item you're looking for, or end a loop if you've finished handling some task (like we're about to do.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for anonymous users\n",
    "\n",
    "Now we have the tools we need to look at the complete history of the Python article; we have the 'continue' tag, we have a set to store our anonymous users in, and we can start writing some code:\n",
    "\n",
    "    parameters = { 'action' : 'query',\n",
    "                   'prop' : 'revisions',\n",
    "                   'titles' : 'Python (programming language)',\n",
    "                   'rvlimit' : 100,\n",
    "                   'rvprop' : 'timestamp|user',\n",
    "                   'format' : 'json',\n",
    "                   'continue' : '' }\n",
    "\n",
    "    anon_editors = set()\n",
    "    while True:\n",
    "        wp_call = requests.get(ENDPOINT, params=parameters)\n",
    "        response = wp_call.json()\n",
    "        for page_id in response['query']['pages']:\n",
    "            revisions = response['query']['pages'][page_id]['revisions']\n",
    "            for rev in revisions:\n",
    "            if 'anon' in rev:\n",
    "                    anon_editors.add(rev['user'])\n",
    "\n",
    "        if 'continue' in response:\n",
    "            parameters['continue'] = response['continue']['continue']\n",
    "            parameters['plcontinue'] = response['continue']['plcontinue']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "Now that we have the number of edits made by anonymous versus logged-in editors, we can sum the number of edits by each, and see the different counts:\n",
    "\n",
    "    anon_edit_count = 0\n",
    "    logged_in_edit_count = 0\n",
    "    for editor in anon_editors:\n",
    "        anon_edit_count += anon_editors[editor]\n",
    "    for editor in logged_in_editors:\n",
    "        logged_in_edit_count += logged_in_editors[editor]\n",
    "\n",
    "    print_params = {'anon_edits' : anon_edit_count,\n",
    "                    'logged_in_edits' : logged_in_edit_count,\n",
    "                    'total_edits' : (anon_edit_count + \n",
    "                                    logged_in_edit_count)}\n",
    "    print(\"Anonymous editors made %anon_edits edits to the Python page, while \"\n",
    "                     \"logged-in editors made %logged_in_edits edits, for a total \"\n",
    "                     \"of %total_edits edits.\" % print_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together. \n",
    "\n",
    "Let's look at the example below together. This example creates a dataset of Wikipedia edits related to The Avengrrs. We can then use this data in the later data analysis/visualization portions of the workshop. \n",
    "\n",
    "\n",
    "Because this takes a while to run, I "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# get_article_revisions is a function that takes an article title in\n",
    "# wikipedia and return a list of all the revisions and meatadata for\n",
    "# that article\n",
    "def get_article_revisions(title):\n",
    "    revisions = []\n",
    "\n",
    "    # create a base url for the api and then a normal url which is initially just a copy of it\n",
    "    wp_api_base = \"http://en.wikipedia.org/w/api.php/?action=query&titles=%(article_title)s&prop=revisions&rvprop=flags|timestamp|user|size|ids&rvlimit=500&format=json\"\n",
    "    wp_api_base = wp_api_base % {'article_title': title }\n",
    "    wp_api_url = wp_api_base\n",
    "\n",
    "    # we'll repeat this forever (i.e., we'll only stop when we find the \"break\" command)\n",
    "    while True:\n",
    "        # the first line open the urls but also handles unicode urls\n",
    "        call = requests.get(wp_api_url)\n",
    "        api_answer = call.json()\n",
    "\n",
    "        # get the list of pages from the json object\n",
    "        pages = api_answer[\"query\"][\"pages\"]\n",
    "\n",
    "        # for every pages (there should always be only one) get the revisions\n",
    "        for page in pages.keys():\n",
    "            if \"revisions\" in pages[page].keys():\n",
    "                query_revisions = pages[page][\"revisions\"]\n",
    "\n",
    "                # for every revision, we do first do cleaning up\n",
    "                for rev in query_revisions:\n",
    "                    # lets continue/skip if the user is hidden\n",
    "                    if \"userhidden\" in rev.keys():\n",
    "                        continue\n",
    "\n",
    "                    # 1: add a title field for the article because we're going to mix them together\n",
    "                    rev[\"title\"] = title\n",
    "\n",
    "                    # 2: lets \"recode\" anon so it's true or false instead of present/missing\n",
    "                    if \"anon\" in rev.keys():\n",
    "                        rev[\"anon\"] = True\n",
    "                    else:\n",
    "                        rev[\"anon\"] = False\n",
    "\n",
    "                    # 3: letst recode \"minor\" in the same way\n",
    "                    if \"minor\" in rev.keys():\n",
    "                        rev[\"minor\"] = True\n",
    "                    else:\n",
    "                        rev[\"minor\"] = False\n",
    "\n",
    "                    # we're going to change the timestamp to make it work a little better in excel and similar\n",
    "                    rev[\"timestamp\"] = rev[\"timestamp\"].replace(\"T\", \" \")\n",
    "                    rev[\"timestamp\"] = rev[\"timestamp\"].replace(\"Z\", \"\")\n",
    "\n",
    "                    # finally save the revisions we've seen to a varaible\n",
    "                    revisions.append(rev)\n",
    "\n",
    "        # if there is a query-continue, it means there are more\n",
    "        if 'query-continue' in api_answer.keys():\n",
    "            # we will grab the rvcontinue token, insert it, and head back to the start of the loop\n",
    "            rvcontinue = api_answer[\"query-continue\"][\"revisions\"][\"rvcontinue\"]\n",
    "            wp_api_url = wp_api_base + \"&rvcontinue=%(continue_from)s\" % {'continue_from' : rvcontinue}\n",
    "        else:\n",
    "            # no continue means we're done\n",
    "            break\n",
    "\n",
    "    # return all the revisions for this page\n",
    "    return(revisions)\n",
    "\n",
    "category = \"Avengers_(comics)\"\n",
    "\n",
    "# we'll use another api called catscan2 to grab a list of pages in\n",
    "# categories and subcategories. it works like the other apis we've\n",
    "# studied!\n",
    "url_catscan = 'http://tools.wmflabs.org/catscan2/catscan2.php?depth=10&categories=%(category)s&doit=1&format=json'\n",
    "url_catscan = url_catscan % {'category' : category}\n",
    "call = requests.get(url_catscan)\n",
    "articles = json.loads(call.content)\n",
    "articles = articles[\"*\"][0][\"a\"][\"*\"]\n",
    "\n",
    "# open a filie to write all the output\n",
    "# output = codecs.open(\"hp_wiki.csv\", \"wb\", \"utf-8\")\n",
    "output = open('avengers_wiki.csv', 'w')\n",
    "\n",
    "output.write(\",\".join([\"title\", \"user\", \"timestamp\", \"size\", \"anon\", \"minor\", \"revid\"]) + \"\\n\")\n",
    "\n",
    "# for every article\n",
    "for article in articles:\n",
    "\n",
    "    # first grab tht title\n",
    "    title = article[\"title\"]\n",
    "\n",
    "    # get the list of revisions from our function and then interating through it printinig it out\n",
    "    revisions = get_article_revisions(title)\n",
    "    for rev in revisions:\n",
    "        output.write(\",\".join(['\"' + rev[\"title\"] + '\"', '\"' + rev[\"user\"] + '\"',\n",
    "                               rev[\"timestamp\"], str(rev[\"size\"]), str(rev[\"anon\"]),\n",
    "                               str(rev[\"minor\"]), str(rev[\"revid\"])]) + \"\\n\")\n",
    "\n",
    "# close the file, we're done here!\n",
    "output.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
